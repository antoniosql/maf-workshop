{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7866ab3",
   "metadata": {},
   "source": [
    "# ðŸ§ª LAB 6 â€“ Workflows + Observabilidad + VisualizaciÃ³n\n",
    "\n",
    "Idea del laboratorio\n",
    "\n",
    "Definimos un agente de Service Desk con ChatAgent (llamando a tu modelo en GitHub).\n",
    "\n",
    "Lo envolvemos en un AgentExecutor (ejecutor integrado del framework).\n",
    "\n",
    "Creamos un TurnManager que:\n",
    "\n",
    "Recibe el texto del usuario.\n",
    "\n",
    "Crea un AgentExecutorRequest con un ChatMessage(Role.USER, text=...).\n",
    "\n",
    "EnvÃ­a esa request al AgentExecutor.\n",
    "\n",
    "Recibe un AgentExecutorResponse y saca el texto final como salida de workflow.\n",
    "\n",
    "Construimos un Workflow con:\n",
    "\n",
    "TurnManager â†’ AgentExecutor â†’ TurnManager\n",
    "\n",
    "Activamos Observabilidad (setup_observability) y visualizamos el workflow con WorkflowViz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3902cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraciÃ³n cargada desde .env\n",
      "  ENDPOINT: https://models.github.ai/inference\n",
      "  MODEL: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_ENDPOINT = os.getenv(\"GITHUB_ENDPOINT\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_MODEL = os.getenv(\"GITHUB_MODEL\")  # ej: gpt-4.1-mini, gpt-4o, etc.\n",
    "\n",
    "if not all([GITHUB_ENDPOINT, GITHUB_TOKEN, GITHUB_MODEL]):\n",
    "    raise RuntimeError(\n",
    "        \"âŒ Faltan variables en .env. Debes definir GITHUB_ENDPOINT, GITHUB_TOKEN y GITHUB_MODEL.\"\n",
    "    )\n",
    "\n",
    "# Adaptar a lo que espera OpenAIChatClient\n",
    "os.environ[\"OPENAI_API_KEY\"] = GITHUB_TOKEN\n",
    "os.environ[\"OPENAI_BASE_URL\"] = GITHUB_ENDPOINT\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = GITHUB_MODEL\n",
    "\n",
    "print(\"âœ… ConfiguraciÃ³n cargada desde .env\")\n",
    "print(\"  ENDPOINT:\", GITHUB_ENDPOINT)\n",
    "print(\"  MODEL:\", GITHUB_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a3c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observabilidad habilitada.\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatAgent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import WorkflowViz\n",
    "from agent_framework.observability import setup_observability\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Activar OpenTelemetry + logs del framework\n",
    "setup_observability(enable_sensitive_data=True)\n",
    "print(\"âœ… Observabilidad habilitada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a5fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChatAgent de Service Desk creado.\n"
     ]
    }
   ],
   "source": [
    "# Creamos el cliente de chat usando las variables OPENAI_*\n",
    "chat_client = OpenAIChatClient()  # lee OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_CHAT_MODEL_ID\n",
    "\n",
    "SERVICE_DESK_INSTRUCTIONS = \"\"\"\n",
    "Eres un agente de Service Desk interno.\n",
    "\n",
    "Tu trabajo es:\n",
    "- Entender la solicitud del usuario en lenguaje natural.\n",
    "- Interpretar si es una duda, una peticiÃ³n de vacaciones, un problema tÃ©cnico, etc.\n",
    "- Responder de forma clara, profesional y en espaÃ±ol.\n",
    "- Si corresponde, indica quÃ© tipo de ticket abrirÃ­as (IT, RRHH, Facilities) y la prioridad sugerida.\n",
    "- No devuelvas JSON, responde en texto libre.\n",
    "\"\"\"\n",
    "\n",
    "service_desk_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    name=\"ServiceDeskAgent\",\n",
    "    instructions=SERVICE_DESK_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "print(\"âœ… ChatAgent de Service Desk creado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc3fdc",
   "metadata": {},
   "source": [
    "AgentExecutor es un ejecutor integrado del framework que sabe:\n",
    "\n",
    "- Recibir AgentExecutorRequest.\n",
    "- Ejecutar el agente (ChatAgent) con esos mensajes.\n",
    "- Emitir AgentExecutorResponse hacia abajo en el workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c2ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AgentExecutor creado para ServiceDeskAgent.\n"
     ]
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=service_desk_agent, id=\"service_desk_exec\")\n",
    "print(\"âœ… AgentExecutor creado para ServiceDeskAgent.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61377b34",
   "metadata": {},
   "source": [
    "TurnManager (Executor que coordina la llamada al agente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8d4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnManager(Executor):\n",
    "    \"\"\"\n",
    "    Executor que coordina la llamada al agente de Service Desk mediante AgentExecutorRequest/Response.\n",
    "\n",
    "    Flujo:\n",
    "    - Primer handler ('start'): recibe el texto del usuario (str) y lo envÃ­a al AgentExecutor\n",
    "      como AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=...)]).\n",
    "    - Segundo handler ('on_agent_response'): recibe AgentExecutorResponse y produce la\n",
    "      salida final del workflow con ctx.yield_output().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id: str | None = None):\n",
    "        super().__init__(id=id or \"turn_manager\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, user_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        \"\"\"\n",
    "        Primer paso del workflow: se llama con el texto del usuario.\n",
    "        Construimos un AgentExecutorRequest con un Ãºnico ChatMessage de rol USER.\n",
    "        \"\"\"\n",
    "        user_msg = ChatMessage(Role.USER, text=user_text)\n",
    "        request = AgentExecutorRequest(messages=[user_msg], should_respond=True)\n",
    "        print(\"ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        result: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[None, str],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Segundo paso: el AgentExecutor responde con AgentExecutorResponse.\n",
    "        AquÃ­ extraemos el texto final y lo emitimos como salida del workflow.\n",
    "        \"\"\"\n",
    "        # AgentExecutorResponse tiene un AgentRunResponse dentro (agent_run_response).\n",
    "        # Extraemos el texto. Si no hubiera .text, extraerÃ­amos del Ãºltimo mensaje.\n",
    "        run_resp = result.agent_run_response\n",
    "        text = getattr(run_resp, \"text\", None)\n",
    "\n",
    "        if not text:\n",
    "            # Fallback: concatenar textos de los mensajes de respuesta\n",
    "            msgs = getattr(run_resp, \"messages\", [])\n",
    "            textos = []\n",
    "            for m in msgs:\n",
    "                if hasattr(m, \"text\") and m.text:\n",
    "                    textos.append(m.text)\n",
    "            text = \"\\n\".join(textos) if textos else \"(sin contenido)\"\n",
    "\n",
    "        print(\"ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\\n\", text)\n",
    "        await ctx.yield_output(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b78ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow construido con TurnManager + AgentExecutor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"workflow.build\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x2ecb1f3182a2064b2afe461384f43f50\",\n",
      "        \"span_id\": \"0x233810dbb5495775\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T12:34:18.514362Z\",\n",
      "    \"end_time\": \"2025-11-28T12:34:18.514999Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"b5e2a07f-19f6-4138-9972-c15c1ebdfff9\",\n",
      "        \"workflow.definition\": \"{\\\"id\\\": \\\"b5e2a07f-19f6-4138-9972-c15c1ebdfff9\\\", \\\"start_executor_id\\\": \\\"turn_manager\\\", \\\"max_iterations\\\": 100, \\\"edge_groups\\\": [{\\\"id\\\": \\\"InternalEdgeGroup/95c94540-5fb3-46c3-bb2d-4599710ab87b\\\", \\\"type\\\": \\\"InternalEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"internal:turn_manager\\\", \\\"target_id\\\": \\\"turn_manager\\\"}]}, {\\\"id\\\": \\\"InternalEdgeGroup/70b43dcc-b01c-4acb-9790-ee4fd113d39d\\\", \\\"type\\\": \\\"InternalEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"internal:service_desk_exec\\\", \\\"target_id\\\": \\\"service_desk_exec\\\"}]}, {\\\"id\\\": \\\"SingleEdgeGroup/47e90068-7cab-42dd-896a-b7c305529356\\\", \\\"type\\\": \\\"SingleEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"turn_manager\\\", \\\"target_id\\\": \\\"service_desk_exec\\\"}]}, {\\\"id\\\": \\\"SingleEdgeGroup/66f383e6-e81e-4962-8fdd-02f5064bc50f\\\", \\\"type\\\": \\\"SingleEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"service_desk_exec\\\", \\\"target_id\\\": \\\"turn_manager\\\"}]}], \\\"executors\\\": {\\\"turn_manager\\\": {\\\"id\\\": \\\"turn_manager\\\", \\\"type\\\": \\\"TurnManager\\\"}, \\\"service_desk_exec\\\": {\\\"id\\\": \\\"service_desk_exec\\\", \\\"type\\\": \\\"AgentExecutor\\\"}}}\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"build.started\",\n",
      "            \"timestamp\": \"2025-11-28T12:34:18.514398Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"build.validation_completed\",\n",
      "            \"timestamp\": \"2025-11-28T12:34:18.514606Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"build.completed\",\n",
      "            \"timestamp\": \"2025-11-28T12:34:18.514986Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "turn_manager = TurnManager(id=\"turn_manager\")\n",
    "\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(turn_manager)\n",
    "    .add_edge(turn_manager, agent_executor)    # TurnManager -> AgentExecutor\n",
    "    .add_edge(agent_executor, turn_manager)    # AgentExecutor -> TurnManager (respuesta)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Workflow construido con TurnManager + AgentExecutor.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122a1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"Â¿CuÃ¡ntos dÃ­as de vacaciones tengo segÃºn la polÃ­tica?\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0x137eed763b303dcb\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x84a4dbf77041aa97\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.540510Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:35.540691Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0x84a4dbf77041aa97\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2dea59ffa2c06bc\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.540357Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:35.540790Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xc557f85704127c5d\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2dea59ffa2c06bc\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.541458Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:35.541510Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/47e90068-7cab-42dd-896a-b7c305529356\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "                \"span_id\": \"0x137eed763b303dcb\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Â¡)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Hola)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=!)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Esta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= consulta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= corresponde)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= al)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Ã¡rea)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Recursos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Humanos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ()\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=RR)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=HH)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=).)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= \n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=La)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= cantidad)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= dÃ­as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= vacaciones)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tienes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= depende)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= polÃ­tica)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= interna)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= empresa)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= y)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= algunos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= casos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= antig)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ã¼)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=edad)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= organizaciÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Te)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= recomendar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ã­a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= revisar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= el)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= manual)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= del)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= empleado)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= contactar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= directamente)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= con)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= RR)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=HH)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= obtener)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= una)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= respuesta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= especÃ­fica)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= \n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= lo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= deseas)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= puedo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= abrir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ticket)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= RR)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=HH)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= te)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= conf)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=men)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= cu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ã¡nt)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=os)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= dÃ­as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= vacaciones)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tienes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= disponibles)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Â¿)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Te)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= gustarÃ­a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= lo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= haga)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=?)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Â¡Hola! Esta consulta corresponde al Ã¡rea de Recursos Humanos (RRHH). \n",
      "\n",
      "La cantidad de dÃ­as de vacaciones que tienes depende de la polÃ­tica interna de la empresa y, en algunos casos, de tu antigÃ¼edad en la organizaciÃ³n. Te recomendarÃ­a revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta especÃ­fica. \n",
      "\n",
      "Si lo deseas, puedo abrir un ticket en RRHH para que te confirmen cuÃ¡ntos dÃ­as de vacaciones tienes disponibles. Â¿Te gustarÃ­a que lo haga?\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Â¡Hola! Esta consulta corresponde al Ã¡rea de Recursos Humanos (RRHH). \n",
      "\n",
      "La cantidad de dÃ­as de vacaciones que tienes depende de la polÃ­tica interna de la empresa y, en algunos casos, de tu antigÃ¼edad en la organizaciÃ³n. Te recomendarÃ­a revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta especÃ­fica. \n",
      "\n",
      "Si lo deseas, puedo abrir un ticket en RRHH para que te confirmen cuÃ¡ntos dÃ­as de vacaciones tienes disponibles. Â¿Te gustarÃ­a que lo haga?, source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Â¡Hola! Esta consulta corresponde al Ã¡rea de Recursos Humanos (RRHH). \n",
      "\n",
      "La cantidad de dÃ­as de vacaciones que tienes depende de la polÃ­tica interna de la empresa y, en algunos casos, de tu antigÃ¼edad en la organizaciÃ³n. Te recomendarÃ­a revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta especÃ­fica. \n",
      "\n",
      "Si lo deseas, puedo abrir un ticket en RRHH para que te confirmen cuÃ¡ntos dÃ­as de vacaciones tienes disponibles. Â¿Te gustarÃ­a que lo haga?\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Â¡)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Gracias)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= por)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= solicitud)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=!)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Esto)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= corresponde)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= una)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= peticiÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= relacionada)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= con)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Recursos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Humanos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ()\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=RR)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=HH)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=).)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=  \n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Voy)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= indic)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=arte)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= los)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= pasos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= bÃ¡sicos)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= suelen)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= seguir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=se)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= este)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= caso)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=:)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=  \n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=1)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= empresa)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tiene)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= sistema)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= especÃ­fico)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= solicitudes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= vacaciones)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ()\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=por)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ejemplo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= portal)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= empleados)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= una)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= herramienta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= como)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Work)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=day)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=),)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= deber)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ã­as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= realizar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= peticiÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= por)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= allÃ­)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= formal)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=izar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=  \n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=2)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= necesitas)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= te)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ista)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= puedo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= abrir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= inmediato)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ticket)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= RR)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=HH)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= indicando)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= solicitud)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= los)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= dÃ­as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= del)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= **)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=1)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= al)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= )\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=15)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= agosto)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=**)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.\n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Por)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= favor)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= confirma)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= quieres)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= lo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= haga)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= y)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= verific)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= es)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= necesario)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= algÃºn)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= otro)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= dato)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= como)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= aprobaciÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= responsable)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= directo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= cualquier)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= otro)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= proceso)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= interno)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Â¡)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Qu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=edo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= at)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=enta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= respuesta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=!)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Â¡Gracias por tu solicitud! Esto corresponde a una peticiÃ³n relacionada con Recursos Humanos (RRHH).  \n",
      "\n",
      "Voy a indicarte los pasos bÃ¡sicos que suelen seguirse en este caso:  \n",
      "1. Si la empresa tiene un sistema especÃ­fico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deberÃ­as realizar la peticiÃ³n por allÃ­ para formalizarla.  \n",
      "2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los dÃ­as del **1 al 15 de agosto**.\n",
      "\n",
      "Por favor, confirma si quieres que lo haga y verifico si es necesario algÃºn otro dato como la aprobaciÃ³n de tu responsable directo o cualquier otro proceso interno. Â¡Quedo atenta a tu respuesta!\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Â¡Gracias por tu solicitud! Esto corresponde a una peticiÃ³n relacionada con Recursos Humanos (RRHH).  \n",
      "\n",
      "Voy a indicarte los pasos bÃ¡sicos que suelen seguirse en este caso:  \n",
      "1. Si la empresa tiene un sistema especÃ­fico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deberÃ­as realizar la peticiÃ³n por allÃ­ para formalizarla.  \n",
      "2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los dÃ­as del **1 al 15 de agosto**.\n",
      "\n",
      "Por favor, confirma si quieres que lo haga y verifico si es necesario algÃºn otro dato como la aprobaciÃ³n de tu responsable directo o cualquier otro proceso interno. Â¡Quedo atenta a tu respuesta!, source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Â¡Gracias por tu solicitud! Esto corresponde a una peticiÃ³n relacionada con Recursos Humanos (RRHH).  \n",
      "\n",
      "Voy a indicarte los pasos bÃ¡sicos que suelen seguirse en este caso:  \n",
      "1. Si la empresa tiene un sistema especÃ­fico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deberÃ­as realizar la peticiÃ³n por allÃ­ para formalizarla.  \n",
      "2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los dÃ­as del **1 al 15 de agosto**.\n",
      "\n",
      "Por favor, confirma si quieres que lo haga y verifico si es necesario algÃºn otro dato como la aprobaciÃ³n de tu responsable directo o cualquier otro proceso interno. Â¡Quedo atenta a tu respuesta!\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"No puedo conectarme a la VPN y tengo una reuniÃ³n urgente con un cliente.\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0x6ec0ee782e10f198\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xe2bab1732a7a9228\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.542433Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.598576Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzDgzxaum2Py7yAvRkK8U1MiXLd\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 115,\n",
      "        \"gen_ai.usage.output_tokens\": 102,\n",
      "        \"gen_ai.client.operation.duration\": 2.0549995000474155,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Hola! Esta consulta corresponde al \\\\u00e1rea de Recursos Humanos (RRHH). \\\\n\\\\nLa cantidad de d\\\\u00edas de vacaciones que tienes depende de la pol\\\\u00edtica interna de la empresa y, en algunos casos, de tu antig\\\\u00fcedad en la organizaci\\\\u00f3n. Te recomendar\\\\u00eda revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta espec\\\\u00edfica. \\\\n\\\\nSi lo deseas, puedo abrir un ticket en RRHH para que te confirmen cu\\\\u00e1ntos d\\\\u00edas de vacaciones tienes disponibles. \\\\u00bfTe gustar\\\\u00eda que lo haga?\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333341788968300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 353,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 238,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 238,\n",
      "                                                \"time_unix_nano\": 1764333340551511700,\n",
      "                                                \"span_id\": 16216510786906769870,\n",
      "                                                \"trace_id\": 225469318533885632739488016997361152945\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333341788968300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 254,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 152,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 152,\n",
      "                                                \"time_unix_nano\": 1764333340551570200,\n",
      "                                                \"span_id\": 16216510786906769870,\n",
      "                                                \"trace_id\": 225469318533885632739488016997361152945\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333341788968300,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 4.886428400175646,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 2.8314289001282305,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 2.0549995000474155,\n",
      "                                                \"time_unix_nano\": 1764333337598414400,\n",
      "                                                \"span_id\": 7980640739636867480,\n",
      "                                                \"trace_id\": 45008091711154499033720836074977673996\n",
      "                                            },\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 2.8314289001282305,\n",
      "                                                \"time_unix_nano\": 1764333340551585100,\n",
      "                                                \"span_id\": 16216510786906769870,\n",
      "                                                \"trace_id\": 225469318533885632739488016997361152945\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xe2bab1732a7a9228\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x9788f6283a31c1ab\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.541738Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.599211Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"gen_ai.agent.id\": \"c09d92cd-3969-452a-aca6-6045253f487d\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzDgzxaum2Py7yAvRkK8U1MiXLd\",\n",
      "        \"gen_ai.usage.input_tokens\": 115,\n",
      "        \"gen_ai.usage.output_tokens\": 102,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Hola! Esta consulta corresponde al \\\\u00e1rea de Recursos Humanos (RRHH). \\\\n\\\\nLa cantidad de d\\\\u00edas de vacaciones que tienes depende de la pol\\\\u00edtica interna de la empresa y, en algunos casos, de tu antig\\\\u00fcedad en la organizaci\\\\u00f3n. Te recomendar\\\\u00eda revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta espec\\\\u00edfica. \\\\n\\\\nSi lo deseas, puedo abrir un ticket en RRHH para que te confirmen cu\\\\u00e1ntos d\\\\u00edas de vacaciones tienes disponibles. \\\\u00bfTe gustar\\\\u00eda que lo haga?\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xeee8e78e64367d86\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x9788f6283a31c1ab\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.599983Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.600071Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0x9788f6283a31c1ab\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2dea59ffa2c06bc\",\n",
      "    \"start_time\": \"2025-11-28T12:35:35.541583Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.600129Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "                \"span_id\": \"0x137eed763b303dcb\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xf3de741d1c1e0677\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2dea59ffa2c06bc\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.651818Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.651885Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/66f383e6-e81e-4962-8fdd-02f5064bc50f\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "                \"span_id\": \"0xeee8e78e64367d86\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xfff583b1c8daf617\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2dea59ffa2c06bc\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.651979Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.652108Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "                \"span_id\": \"0xeee8e78e64367d86\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x21dc3e3f8333a044987802f0c618c30c\",\n",
      "        \"span_id\": \"0xd2dea59ffa2c06bc\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T12:35:35.540088Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.717022Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"b5e2a07f-19f6-4138-9972-c15c1ebdfff9\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:35.540128Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:37.716988Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xa221fe4fc51765e0\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0xdc9d36356d7523be\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.717972Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.718019Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xdc9d36356d7523be\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xa88b7697b71571c4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.717841Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.718033Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xdb59fd5c559dbc34\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xa88b7697b71571c4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.718920Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:37.718952Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/47e90068-7cab-42dd-896a-b7c305529356\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "                \"span_id\": \"0xa221fe4fc51765e0\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xe10c9ea455de49ce\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x8f005df1a652de63\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.719383Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.551767Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Hola! Esta consulta corresponde al \\\\u00e1rea de Recursos Humanos (RRHH). \\\\n\\\\nLa cantidad de d\\\\u00edas de vacaciones que tienes depende de la pol\\\\u00edtica interna de la empresa y, en algunos casos, de tu antig\\\\u00fcedad en la organizaci\\\\u00f3n. Te recomendar\\\\u00eda revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta espec\\\\u00edfica. \\\\n\\\\nSi lo deseas, puedo abrir un ticket en RRHH para que te confirmen cu\\\\u00e1ntos d\\\\u00edas de vacaciones tienes disponibles. \\\\u00bfTe gustar\\\\u00eda que lo haga?\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzF7BJU2X6OoSJPbJ0hwPkLRwpH\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 238,\n",
      "        \"gen_ai.usage.output_tokens\": 152,\n",
      "        \"gen_ai.client.operation.duration\": 2.8314289001282305,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Gracias por tu solicitud! Esto corresponde a una petici\\\\u00f3n relacionada con Recursos Humanos (RRHH).  \\\\n\\\\nVoy a indicarte los pasos b\\\\u00e1sicos que suelen seguirse en este caso:  \\\\n1. Si la empresa tiene un sistema espec\\\\u00edfico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deber\\\\u00edas realizar la petici\\\\u00f3n por all\\\\u00ed para formalizarla.  \\\\n2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los d\\\\u00edas del **1 al 15 de agosto**.\\\\n\\\\nPor favor, confirma si quieres que lo haga y verifico si es necesario alg\\\\u00fan otro dato como la aprobaci\\\\u00f3n de tu responsable directo o cualquier otro proceso interno. \\\\u00a1Quedo atenta a tu respuesta!\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0x8f005df1a652de63\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x542232dc83d79ab6\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.719108Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.552743Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"gen_ai.agent.id\": \"c09d92cd-3969-452a-aca6-6045253f487d\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzF7BJU2X6OoSJPbJ0hwPkLRwpH\",\n",
      "        \"gen_ai.usage.input_tokens\": 238,\n",
      "        \"gen_ai.usage.output_tokens\": 152,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Gracias por tu solicitud! Esto corresponde a una petici\\\\u00f3n relacionada con Recursos Humanos (RRHH).  \\\\n\\\\nVoy a indicarte los pasos b\\\\u00e1sicos que suelen seguirse en este caso:  \\\\n1. Si la empresa tiene un sistema espec\\\\u00edfico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deber\\\\u00edas realizar la petici\\\\u00f3n por all\\\\u00ed para formalizarla.  \\\\n2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los d\\\\u00edas del **1 al 15 de agosto**.\\\\n\\\\nPor favor, confirma si quieres que lo haga y verifico si es necesario alg\\\\u00fan otro dato como la aprobaci\\\\u00f3n de tu responsable directo o cualquier otro proceso interno. \\\\u00a1Quedo atenta a tu respuesta!\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0x5213ca54d220e784\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x542232dc83d79ab6\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.553175Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.553212Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0x542232dc83d79ab6\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xa88b7697b71571c4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:37.719011Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.553244Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "                \"span_id\": \"0xa221fe4fc51765e0\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xa237d499b6430153\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xa88b7697b71571c4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.616823Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.616871Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/66f383e6-e81e-4962-8fdd-02f5064bc50f\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "                \"span_id\": \"0x5213ca54d220e784\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0x66a69799612817cd\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xa88b7697b71571c4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.616963Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.617083Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "                \"span_id\": \"0x5213ca54d220e784\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xa99fcfab7dc53bc0d451c1a389bc73b1\",\n",
      "        \"span_id\": \"0xa88b7697b71571c4\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T12:35:37.717674Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.683056Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"b5e2a07f-19f6-4138-9972-c15c1ebdfff9\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:37.717689Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:40.683043Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x53ceaa661065bdab\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x8e399e979d018be4\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683582Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.683612Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x8e399e979d018be4\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x5aff778053aeae1f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683498Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.683625Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x52b3b883abe135d6\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x5aff778053aeae1f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683819Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:40.683845Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/47e90068-7cab-42dd-896a-b7c305529356\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "                \"span_id\": \"0x53ceaa661065bdab\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ent)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=endido)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= parece)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= estÃ¡s)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= enfrent)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ando)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= problema)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tÃ©cnico)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= crÃ­tico)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Este)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= incidente)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= estÃ¡)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= relacionado)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= con)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= el)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Ã¡rea)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= TI)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ()\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=IT)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=).\n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=**)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Pas)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=os)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= puedes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= intentar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= mientras)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tanto)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=:)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=**\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=1)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Ver)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ifica)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tienes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= conexiÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Internet)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= dispositivo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= \n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=2)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= A)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=seg)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ãº)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=rate)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= estar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ingres)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ando)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= las)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= cred)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=enciales)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= correct)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= VPN)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=3)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= recientemente)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= camb)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ias)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=te)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= contraseÃ±a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= acceso)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= aseg)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Ãº)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=rate)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= actualizar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= en)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= configuraciÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= de)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= VPN)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=4)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Rein)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=icia)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= equipo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= y)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= vuelve)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= intentar)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= conect)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=arte)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.\n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=D)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ado)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= mencion)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=as)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= reuniÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= es)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= urgente)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= voy)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= a)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= suger)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= este)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ticket)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= como)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= **)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Alta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Prior)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=idad)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=**)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= rec)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=iba)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= atenciÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= rÃ¡pida)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Por)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= favor)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= confirma)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= deseas)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= que)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= lo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= esc)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ale)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= si)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= tienes)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= un)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= canal)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= altern)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ativo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= conect)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=arte)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= como)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= compartir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= pantalla)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= mediante)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= otra)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= plataforma)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ()\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Zoom)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= Teams)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=,)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= etc)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.))\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= mientras)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= res)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=uel)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=ven)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= el)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= problema)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.\n",
      "\n",
      ")\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=Qu)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=edo)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= at)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=enta)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= para)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= asistir)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= con)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= la)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= gestiÃ³n)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= del)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= ticket)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= o)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= con)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= mÃ¡s)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= soporte)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages= adicional)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=.)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: AgentRunUpdateEvent(executor_id=service_desk_exec, messages=)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Entendido, parece que estÃ¡s enfrentando un problema tÃ©cnico crÃ­tico. Este incidente estÃ¡ relacionado con el Ã¡rea de TI (IT).\n",
      "\n",
      "**Pasos que puedes intentar mientras tanto:**\n",
      "1. Verifica si tienes conexiÃ³n a Internet en tu dispositivo. \n",
      "2. AsegÃºrate de estar ingresando las credenciales correctas para la VPN.\n",
      "3. Si recientemente cambiaste tu contraseÃ±a de acceso, asegÃºrate de actualizarla en la configuraciÃ³n de la VPN.\n",
      "4. Reinicia tu equipo y vuelve a intentar conectarte.\n",
      "\n",
      "Dado que mencionas que la reuniÃ³n es urgente, voy a sugerir este ticket como **Alta Prioridad** para que reciba atenciÃ³n rÃ¡pida. Por favor, confirma si deseas que lo escale o si tienes un canal alternativo para conectarte, como compartir pantalla mediante otra plataforma (Zoom, Teams, etc.) mientras resuelven el problema.\n",
      "\n",
      "Quedo atenta para asistir con la gestiÃ³n del ticket o con mÃ¡s soporte adicional.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Entendido, parece que estÃ¡s enfrentando un problema tÃ©cnico crÃ­tico. Este incidente estÃ¡ relacionado con el Ã¡rea de TI (IT).\n",
      "\n",
      "**Pasos que puedes intentar mientras tanto:**\n",
      "1. Verifica si tienes conexiÃ³n a Internet en tu dispositivo. \n",
      "2. AsegÃºrate de estar ingresando las credenciales correctas para la VPN.\n",
      "3. Si recientemente cambiaste tu contraseÃ±a de acceso, asegÃºrate de actualizarla en la configuraciÃ³n de la VPN.\n",
      "4. Reinicia tu equipo y vuelve a intentar conectarte.\n",
      "\n",
      "Dado que mencionas que la reuniÃ³n es urgente, voy a sugerir este ticket como **Alta Prioridad** para que reciba atenciÃ³n rÃ¡pida. Por favor, confirma si deseas que lo escale o si tienes un canal alternativo para conectarte, como compartir pantalla mediante otra plataforma (Zoom, Teams, etc.) mientras resuelven el problema.\n",
      "\n",
      "Quedo atenta para asistir con la gestiÃ³n del ticket o con mÃ¡s soporte adicional., source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Entendido, parece que estÃ¡s enfrentando un problema tÃ©cnico crÃ­tico. Este incidente estÃ¡ relacionado con el Ã¡rea de TI (IT).\n",
      "\n",
      "**Pasos que puedes intentar mientras tanto:**\n",
      "1. Verifica si tienes conexiÃ³n a Internet en tu dispositivo. \n",
      "2. AsegÃºrate de estar ingresando las credenciales correctas para la VPN.\n",
      "3. Si recientemente cambiaste tu contraseÃ±a de acceso, asegÃºrate de actualizarla en la configuraciÃ³n de la VPN.\n",
      "4. Reinicia tu equipo y vuelve a intentar conectarte.\n",
      "\n",
      "Dado que mencionas que la reuniÃ³n es urgente, voy a sugerir este ticket como **Alta Prioridad** para que reciba atenciÃ³n rÃ¡pida. Por favor, confirma si deseas que lo escale o si tienes un canal alternativo para conectarte, como compartir pantalla mediante otra plataforma (Zoom, Teams, etc.) mientras resuelven el problema.\n",
      "\n",
      "Quedo atenta para asistir con la gestiÃ³n del ticket o con mÃ¡s soporte adicional.\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x2b65d2a1912c7e7f\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x1ba9a78adce9f375\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.684246Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.180660Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Hola! Esta consulta corresponde al \\\\u00e1rea de Recursos Humanos (RRHH). \\\\n\\\\nLa cantidad de d\\\\u00edas de vacaciones que tienes depende de la pol\\\\u00edtica interna de la empresa y, en algunos casos, de tu antig\\\\u00fcedad en la organizaci\\\\u00f3n. Te recomendar\\\\u00eda revisar el manual del empleado o contactar directamente con RRHH para obtener una respuesta espec\\\\u00edfica. \\\\n\\\\nSi lo deseas, puedo abrir un ticket en RRHH para que te confirmen cu\\\\u00e1ntos d\\\\u00edas de vacaciones tienes disponibles. \\\\u00bfTe gustar\\\\u00eda que lo haga?\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00a1Gracias por tu solicitud! Esto corresponde a una petici\\\\u00f3n relacionada con Recursos Humanos (RRHH).  \\\\n\\\\nVoy a indicarte los pasos b\\\\u00e1sicos que suelen seguirse en este caso:  \\\\n1. Si la empresa tiene un sistema espec\\\\u00edfico para solicitudes de vacaciones (por ejemplo, un portal de empleados o una herramienta como Workday), deber\\\\u00edas realizar la petici\\\\u00f3n por all\\\\u00ed para formalizarla.  \\\\n2. Si necesitas que te asista, puedo abrir de inmediato un ticket en RRHH indicando tu solicitud para los d\\\\u00edas del **1 al 15 de agosto**.\\\\n\\\\nPor favor, confirma si quieres que lo haga y verifico si es necesario alg\\\\u00fan otro dato como la aprobaci\\\\u00f3n de tu responsable directo o cualquier otro proceso interno. \\\\u00a1Quedo atenta a tu respuesta!\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"No puedo conectarme a la VPN y tengo una reuni\\\\u00f3n urgente con un cliente.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzIjobOROB3z07MEZf9zzEvmBdy\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 413,\n",
      "        \"gen_ai.usage.output_tokens\": 195,\n",
      "        \"gen_ai.client.operation.duration\": 5.495423799846321,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, parece que est\\\\u00e1s enfrentando un problema t\\\\u00e9cnico cr\\\\u00edtico. Este incidente est\\\\u00e1 relacionado con el \\\\u00e1rea de TI (IT).\\\\n\\\\n**Pasos que puedes intentar mientras tanto:**\\\\n1. Verifica si tienes conexi\\\\u00f3n a Internet en tu dispositivo. \\\\n2. Aseg\\\\u00farate de estar ingresando las credenciales correctas para la VPN.\\\\n3. Si recientemente cambiaste tu contrase\\\\u00f1a de acceso, aseg\\\\u00farate de actualizarla en la configuraci\\\\u00f3n de la VPN.\\\\n4. Reinicia tu equipo y vuelve a intentar conectarte.\\\\n\\\\nDado que mencionas que la reuni\\\\u00f3n es urgente, voy a sugerir este ticket como **Alta Prioridad** para que reciba atenci\\\\u00f3n r\\\\u00e1pida. Por favor, confirma si deseas que lo escale o si tienes un canal alternativo para conectarte, como compartir pantalla mediante otra plataforma (Zoom, Teams, etc.) mientras resuelven el problema.\\\\n\\\\nQuedo atenta para asistir con la gesti\\\\u00f3n del ticket o con m\\\\u00e1s soporte adicional.\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333346814428700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 413,\n",
      "                                                \"time_unix_nano\": 1764333346180500500,\n",
      "                                                \"span_id\": 3127137107645857407,\n",
      "                                                \"trace_id\": 5308615970898335826127828628688916021\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333346814428700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 195,\n",
      "                                                \"time_unix_nano\": 1764333346180542000,\n",
      "                                                \"span_id\": 3127137107645857407,\n",
      "                                                \"trace_id\": 5308615970898335826127828628688916021\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333346814428700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 5.495423799846321,\n",
      "                                                \"time_unix_nano\": 1764333346180554100,\n",
      "                                                \"span_id\": 3127137107645857407,\n",
      "                                                \"trace_id\": 5308615970898335826127828628688916021\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x1ba9a78adce9f375\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xe3cbb0dd2fe90b0f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683974Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.181656Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"No puedo conectarme a la VPN y tengo una reuni\\\\u00f3n urgente con un cliente.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"gen_ai.agent.id\": \"c09d92cd-3969-452a-aca6-6045253f487d\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgrzIjobOROB3z07MEZf9zzEvmBdy\",\n",
      "        \"gen_ai.usage.input_tokens\": 413,\n",
      "        \"gen_ai.usage.output_tokens\": 195,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, parece que est\\\\u00e1s enfrentando un problema t\\\\u00e9cnico cr\\\\u00edtico. Este incidente est\\\\u00e1 relacionado con el \\\\u00e1rea de TI (IT).\\\\n\\\\n**Pasos que puedes intentar mientras tanto:**\\\\n1. Verifica si tienes conexi\\\\u00f3n a Internet en tu dispositivo. \\\\n2. Aseg\\\\u00farate de estar ingresando las credenciales correctas para la VPN.\\\\n3. Si recientemente cambiaste tu contrase\\\\u00f1a de acceso, aseg\\\\u00farate de actualizarla en la configuraci\\\\u00f3n de la VPN.\\\\n4. Reinicia tu equipo y vuelve a intentar conectarte.\\\\n\\\\nDado que mencionas que la reuni\\\\u00f3n es urgente, voy a sugerir este ticket como **Alta Prioridad** para que reciba atenci\\\\u00f3n r\\\\u00e1pida. Por favor, confirma si deseas que lo escale o si tienes un canal alternativo para conectarte, como compartir pantalla mediante otra plataforma (Zoom, Teams, etc.) mientras resuelven el problema.\\\\n\\\\nQuedo atenta para asistir con la gesti\\\\u00f3n del ticket o con m\\\\u00e1s soporte adicional.\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x8f15b1f9c69742ae\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0xe3cbb0dd2fe90b0f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:46.182137Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.182170Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0xe3cbb0dd2fe90b0f\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x5aff778053aeae1f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683893Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.182192Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "                \"span_id\": \"0x53ceaa661065bdab\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x44c592f1dff8e985\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x5aff778053aeae1f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:46.233643Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.233679Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/66f383e6-e81e-4962-8fdd-02f5064bc50f\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "                \"span_id\": \"0x8f15b1f9c69742ae\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0xef100a15228edd50\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x5aff778053aeae1f\",\n",
      "    \"start_time\": \"2025-11-28T12:35:46.233776Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.233845Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"MessageType.STANDARD\",\n",
      "        \"message.payload_type\": \"Message\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "                \"span_id\": \"0x8f15b1f9c69742ae\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x03fe66f99ab8789e4f31fa7be328ce35\",\n",
      "        \"span_id\": \"0x5aff778053aeae1f\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T12:35:40.683389Z\",\n",
      "    \"end_time\": \"2025-11-28T12:35:46.287007Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"b5e2a07f-19f6-4138-9972-c15c1ebdfff9\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:40.683400Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T12:35:46.286985Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333351824552000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333351824552000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333351824552000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333356831599700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333356831599700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333356831599700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333361836336800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333361836336800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333361836336800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333366845029100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333366845029100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333366845029100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333371850027500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333371850027500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333371850027500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333376850216800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333376850216800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333376850216800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333381854536000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333381854536000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333381854536000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333386863045200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333386863045200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333386863045200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333391881477400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333391881477400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333391881477400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333396884734700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333396884734700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333396884734700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333401903641700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333401903641700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333401903641700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333406916271900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333406916271900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333406916271900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333411937050700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333411937050700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333411937050700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333416941539100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333416941539100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333416941539100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333421948390900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333421948390900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333421948390900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333426951615300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333426951615300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333426951615300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333431955954800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333431955954800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333431955954800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333436965110000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333436965110000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333436965110000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def run_service_desk_workflow(input_text: str):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ðŸš€ Ejecutando workflow Service Desk con input:\\n\\\"{input_text}\\\"\\n\")\n",
    "\n",
    "    async for event in workflow.run_stream(input_text):\n",
    "        print(\"ðŸ“¡ Evento:\", event)\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(\"\\nâœ… Resultado final del workflow:\\n\")\n",
    "            print(event.data)\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# Pruebas\n",
    "await run_service_desk_workflow(\"Â¿CuÃ¡ntos dÃ­as de vacaciones tengo segÃºn la polÃ­tica?\")\n",
    "await run_service_desk_workflow(\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\")\n",
    "await run_service_desk_workflow(\"No puedo conectarme a la VPN y tengo una reuniÃ³n urgente con un cliente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f198b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“œ Diagrama Mermaid:\n",
      "\n",
      "flowchart TD\n",
      "  turn_manager[\"turn_manager (Start)\"];\n",
      "  service_desk_exec[\"service_desk_exec\"];\n",
      "  internal_turn_manager --> turn_manager;\n",
      "  internal_service_desk_exec --> service_desk_exec;\n",
      "  turn_manager --> service_desk_exec;\n",
      "  service_desk_exec --> turn_manager;\n",
      "\n",
      "ðŸ“œ Diagrama DOT:\n",
      "\n",
      "digraph Workflow {\n",
      "  rankdir=TD;\n",
      "  node [shape=box, style=filled, fillcolor=lightblue];\n",
      "  edge [color=black, arrowhead=vee];\n",
      "\n",
      "  \"turn_manager\" [fillcolor=lightgreen, label=\"turn_manager\\n(Start)\"];\n",
      "  \"service_desk_exec\" [label=\"service_desk_exec\"];\n",
      "  \"internal:turn_manager\" -> \"turn_manager\";\n",
      "  \"internal:service_desk_exec\" -> \"service_desk_exec\";\n",
      "  \"turn_manager\" -> \"service_desk_exec\";\n",
      "  \"service_desk_exec\" -> \"turn_manager\";\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333441977669900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333441977669900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333441977669900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333446982980300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333446982980300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333446982980300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333451994458400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333451994458400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333451994458400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333456998893000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333456998893000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333456998893000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333462001462700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333462001462700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333462001462700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333467016127100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333467016127100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333467016127100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333472022076200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333472022076200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333472022076200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333477033734500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333477033734500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333477033734500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333482034444300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333482034444300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333482034444300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333487049146200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333487049146200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333487049146200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333492049452500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333492049452500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333492049452500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333497063402000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333497063402000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333497063402000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333502065911100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333502065911100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333502065911100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333507082781400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333507082781400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333507082781400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333512089489400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333512089489400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333512089489400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333517091862800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333517091862800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333517091862800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333522096073200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333522096073200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333522096073200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333527100044000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333527100044000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333527100044000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333532112994600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333532112994600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333532112994600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333537123599000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333537123599000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333537123599000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333542134763500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333542134763500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333542134763500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333547145982700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333547145982700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333547145982700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333552163452300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333552163452300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333552163452300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333557178928700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333557178928700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333557178928700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333562190222000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333562190222000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333562190222000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333567203584800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333567203584800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333567203584800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333572215988400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333572215988400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333572215988400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333577220149900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333577220149900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333577220149900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333582224875600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333582224875600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333582224875600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333587236576800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333587236576800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333587236576800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333592239064200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333592239064200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333592239064200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333597252306000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333597252306000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333597252306000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333602262098100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333602262098100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333602262098100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333607284187900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333607284187900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333607284187900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333612289198500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333612289198500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333612289198500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333617290785700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333617290785700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333617290785700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333622300648200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333622300648200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333622300648200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333627310626300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333627310626300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333627310626300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333632325911800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333632325911800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333632325911800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333637338254400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333637338254400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333637338254400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333642350803100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333642350803100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333642350803100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333647365892000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333647365892000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333647365892000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333652369708500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333652369708500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333652369708500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333657379125800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333657379125800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333657379125800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333662382455300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333662382455300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333662382455300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333667383850600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333667383850600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333667383850600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333672389592900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333672389592900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333672389592900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333677399054400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333677399054400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333677399054400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333682399469000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333682399469000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333682399469000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333687415254100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333687415254100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333687415254100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333692431611400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333692431611400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333692431611400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333697448476200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333697448476200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333697448476200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333702453618900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333702453618900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333702453618900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333707465128000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333707465128000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333707465128000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333712479599400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333712479599400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333712479599400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333717483671300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333717483671300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333717483671300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333722495130800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333722495130800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333722495130800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333727512920500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333727512920500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333727512920500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333732514734000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333732514734000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333732514734000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333737521269100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333737521269100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333737521269100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333742531740900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333742531740900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333742531740900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333747540846900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333747540846900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333747540846900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333752551476600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333752551476600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333752551476600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333757566490200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333757566490200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333757566490200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333762579594700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333762579594700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333762579594700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333767594253600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333767594253600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333767594253600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333772599857400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333772599857400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333772599857400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333777612846700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333777612846700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333777612846700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333782615185000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333782615185000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333782615185000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333787617837300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333787617837300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333787617837300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333792617808900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333792617808900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333792617808900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333797622526100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333797622526100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333797622526100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333802633922700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333802633922700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333802633922700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333807642158800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333807642158800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333807642158800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333812660549600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333812660549600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333812660549600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333817674569800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333817674569800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333817674569800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333822682691400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333822682691400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333822682691400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333827692866600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333827692866600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333827692866600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333832697093500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333832697093500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333832697093500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333837699238600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333837699238600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333837699238600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333842715907900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333842715907900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333842715907900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333847730834300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333847730834300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333847730834300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333852734492200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333852734492200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333852734492200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333857748206500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333857748206500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333857748206500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333862753080900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333862753080900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333862753080900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333867767138300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333867767138300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333867767138300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333872767257400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333872767257400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333872767257400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333877767927200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333877767927200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333877767927200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333882783584200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333882783584200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333882783584200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333887788424100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333887788424100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333887788424100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333892799037100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333892799037100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333892799037100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333897801164800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333897801164800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333897801164800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333902814911200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333902814911200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333902814911200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333907831806600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333907831806600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333907831806600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333912838563000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333912838563000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333912838563000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333917849127000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333917849127000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333917849127000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333922864999900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333922864999900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333922864999900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333927867017400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333927867017400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333927867017400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333932881442900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333932881442900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333932881442900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333937885134300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333937885134300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333937885134300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333942886232400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333942886232400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333942886232400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333947894411100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333947894411100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333947894411100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333952899145100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333952899145100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333952899145100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333957902900700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333957902900700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333957902900700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333962915281100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333962915281100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333962915281100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333967933124700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333967933124700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333967933124700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333972950193100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333972950193100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333972950193100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333977965060200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333977965060200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333977965060200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333982981430600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333982981430600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333982981430600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333987997804300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333987997804300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333987997804300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333993002686300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333993002686300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333993002686300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764333998015994200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764333998015994200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764333998015994200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334003032375000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334003032375000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334003032375000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334008048139700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334008048139700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334008048139700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334013065164500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334013065164500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334013065164500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334018081890200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334018081890200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334018081890200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334023098691500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334023098691500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334023098691500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334028100465200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334028100465200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334028100465200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334033100658500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334033100658500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334033100658500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334038116327400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334038116327400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334038116327400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334043131503100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334043131503100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334043131503100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334048133586100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334048133586100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334048133586100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334053133690200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334053133690200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334053133690200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334058149081200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334058149081200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334058149081200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334063165839700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334063165839700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334063165839700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334068181729800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334068181729800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334068181729800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334073199265400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334073199265400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334073199265400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334078214703100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334078214703100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334078214703100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334083231844700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334083231844700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334083231844700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598344100,\n",
      "                                        \"time_unix_nano\": 1764334088247529800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 766,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 115,\n",
      "                                        \"max\": 413,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598397700,\n",
      "                                        \"time_unix_nano\": 1764334088247529800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 449,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 102,\n",
      "                                        \"max\": 195,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764333337598457500,\n",
      "                                        \"time_unix_nano\": 1764334088247529800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 10.381852200021967,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.0549995000474155,\n",
      "                                        \"max\": 5.495423799846321,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "viz = WorkflowViz(workflow)\n",
    "\n",
    "print(\"ðŸ“œ Diagrama Mermaid:\\n\")\n",
    "print(viz.to_mermaid())\n",
    "\n",
    "print(\"\\nðŸ“œ Diagrama DOT:\\n\")\n",
    "print(viz.to_digraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Requiere graphviz instalado en el sistema para exportar a SVG y PNG\n",
    "# https://graphviz.org/download/ \n",
    "\n",
    "# Exportar a SVG\n",
    "svg_path = viz.export(format=\"svg\")\n",
    "print(\"âœ… SVG generado en:\", svg_path)\n",
    "\n",
    "# Exportar a PNG\n",
    "png_path = viz.export(format=\"png\")\n",
    "print(\"âœ… PNG generado en:\", png_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
