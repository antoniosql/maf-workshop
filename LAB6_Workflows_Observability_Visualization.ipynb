{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7866ab3",
   "metadata": {},
   "source": [
    "# ðŸ§ª LAB 6 â€“ Workflows + Observabilidad + VisualizaciÃ³n\n",
    "\n",
    "Idea del laboratorio\n",
    "\n",
    "Definimos un agente de Service Desk con ChatAgent (llamando a tu modelo en GitHub).\n",
    "\n",
    "Lo envolvemos en un AgentExecutor (ejecutor integrado del framework).\n",
    "\n",
    "Creamos un TurnManager que:\n",
    "\n",
    "Recibe el texto del usuario.\n",
    "\n",
    "Crea un AgentExecutorRequest con un ChatMessage(Role.USER, text=...).\n",
    "\n",
    "EnvÃ­a esa request al AgentExecutor.\n",
    "\n",
    "Recibe un AgentExecutorResponse y saca el texto final como salida de workflow.\n",
    "\n",
    "Construimos un Workflow con:\n",
    "\n",
    "TurnManager â†’ AgentExecutor â†’ TurnManager\n",
    "\n",
    "Activamos Observabilidad (setup_observability) y visualizamos el workflow con WorkflowViz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3902cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ConfiguraciÃ³n cargada desde .env\n",
      "  ENDPOINT: https://models.github.ai/inference\n",
      "  MODEL: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_ENDPOINT = os.getenv(\"GITHUB_ENDPOINT\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_MODEL = os.getenv(\"GITHUB_MODEL\")  # ej: gpt-4.1-mini, gpt-4o, etc.\n",
    "\n",
    "if not all([GITHUB_ENDPOINT, GITHUB_TOKEN, GITHUB_MODEL]):\n",
    "    raise RuntimeError(\n",
    "        \"âŒ Faltan variables en .env. Debes definir GITHUB_ENDPOINT, GITHUB_TOKEN y GITHUB_MODEL.\"\n",
    "    )\n",
    "\n",
    "# Adaptar a lo que espera OpenAIChatClient\n",
    "os.environ[\"OPENAI_API_KEY\"] = GITHUB_TOKEN\n",
    "os.environ[\"OPENAI_BASE_URL\"] = GITHUB_ENDPOINT\n",
    "os.environ[\"OPENAI_CHAT_MODEL_ID\"] = GITHUB_MODEL\n",
    "\n",
    "print(\"âœ… ConfiguraciÃ³n cargada desde .env\")\n",
    "print(\"  ENDPOINT:\", GITHUB_ENDPOINT)\n",
    "print(\"  MODEL:\", GITHUB_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57a3c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Observabilidad habilitada.\n"
     ]
    }
   ],
   "source": [
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatAgent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework import WorkflowViz\n",
    "from agent_framework.observability import setup_observability\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Activar OpenTelemetry + logs del framework\n",
    "setup_observability(enable_sensitive_data=True)\n",
    "print(\"âœ… Observabilidad habilitada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7a5fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChatAgent de Service Desk creado.\n"
     ]
    }
   ],
   "source": [
    "# Creamos el cliente de chat usando las variables OPENAI_*\n",
    "chat_client = OpenAIChatClient()  # lee OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_CHAT_MODEL_ID\n",
    "\n",
    "SERVICE_DESK_INSTRUCTIONS = \"\"\"\n",
    "Eres un agente de Service Desk interno.\n",
    "\n",
    "Tu trabajo es:\n",
    "- Entender la solicitud del usuario en lenguaje natural.\n",
    "- Interpretar si es una duda, una peticiÃ³n de vacaciones, un problema tÃ©cnico, etc.\n",
    "- Responder de forma clara, profesional y en espaÃ±ol.\n",
    "- Si corresponde, indica quÃ© tipo de ticket abrirÃ­as (IT, RRHH, Facilities) y la prioridad sugerida.\n",
    "- No devuelvas JSON, responde en texto libre.\n",
    "\"\"\"\n",
    "\n",
    "service_desk_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    name=\"ServiceDeskAgent\",\n",
    "    instructions=SERVICE_DESK_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "print(\"âœ… ChatAgent de Service Desk creado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc3fdc",
   "metadata": {},
   "source": [
    "AgentExecutor es un ejecutor integrado del framework que sabe:\n",
    "\n",
    "- Recibir AgentExecutorRequest.\n",
    "- Ejecutar el agente (ChatAgent) con esos mensajes.\n",
    "- Emitir AgentExecutorResponse hacia abajo en el workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49c2ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AgentExecutor creado para ServiceDeskAgent.\n"
     ]
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(agent=service_desk_agent, id=\"service_desk_exec\")\n",
    "print(\"âœ… AgentExecutor creado para ServiceDeskAgent.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61377b34",
   "metadata": {},
   "source": [
    "TurnManager (Executor que coordina la llamada al agente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8d4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnManager(Executor):\n",
    "    \"\"\"\n",
    "    Executor que coordina la llamada al agente de Service Desk mediante AgentExecutorRequest/Response.\n",
    "\n",
    "    Flujo:\n",
    "    - Primer handler ('start'): recibe el texto del usuario (str) y lo envÃ­a al AgentExecutor\n",
    "      como AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=...)]).\n",
    "    - Segundo handler ('on_agent_response'): recibe AgentExecutorResponse y produce la\n",
    "      salida final del workflow con ctx.yield_output().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id: str | None = None):\n",
    "        super().__init__(id=id or \"turn_manager\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, user_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        \"\"\"\n",
    "        Primer paso del workflow: se llama con el texto del usuario.\n",
    "        Construimos un AgentExecutorRequest con un Ãºnico ChatMessage de rol USER.\n",
    "        \"\"\"\n",
    "        user_msg = ChatMessage(Role.USER, text=user_text)\n",
    "        request = AgentExecutorRequest(messages=[user_msg], should_respond=True)\n",
    "        print(\"ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        result: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[None, str],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Segundo paso: el AgentExecutor responde con AgentExecutorResponse.\n",
    "        AquÃ­ extraemos el texto final y lo emitimos como salida del workflow.\n",
    "        \"\"\"\n",
    "        # AgentExecutorResponse tiene un AgentRunResponse dentro (agent_run_response).\n",
    "        # Extraemos el texto. Si no hubiera .text, extraerÃ­amos del Ãºltimo mensaje.\n",
    "        run_resp = result.agent_run_response\n",
    "        text = getattr(run_resp, \"text\", None)\n",
    "\n",
    "        if not text:\n",
    "            # Fallback: concatenar textos de los mensajes de respuesta\n",
    "            msgs = getattr(run_resp, \"messages\", [])\n",
    "            textos = []\n",
    "            for m in msgs:\n",
    "                if hasattr(m, \"text\") and m.text:\n",
    "                    textos.append(m.text)\n",
    "            text = \"\\n\".join(textos) if textos else \"(sin contenido)\"\n",
    "\n",
    "        print(\"ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\\n\", text)\n",
    "        await ctx.yield_output(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60b78ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-28 05:53:44 - c:\\Repos\\agent-framework-workshop\\.venv\\Lib\\site-packages\\agent_framework\\_workflows\\_validation.py:520 - WARNING] Cycle detected in the workflow graph involving: service_desk_exec -> turn_manager -> service_desk_exec. Ensure termination or iteration limits exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow construido con TurnManager + AgentExecutor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"workflow.build\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x42cb48ba72c8289c4ce815ced3789a4f\",\n",
      "        \"span_id\": \"0x8d3b4210f7f6c626\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T04:53:44.132347Z\",\n",
      "    \"end_time\": \"2025-11-28T04:53:44.141386Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"5da74c79-fe87-452b-a79b-585ef1426f0e\",\n",
      "        \"workflow.definition\": \"{\\\"id\\\": \\\"5da74c79-fe87-452b-a79b-585ef1426f0e\\\", \\\"start_executor_id\\\": \\\"turn_manager\\\", \\\"max_iterations\\\": 100, \\\"edge_groups\\\": [{\\\"id\\\": \\\"SingleEdgeGroup/f56c0dde-53cd-4aa6-90d0-e946390f7a76\\\", \\\"type\\\": \\\"SingleEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"turn_manager\\\", \\\"target_id\\\": \\\"service_desk_exec\\\"}]}, {\\\"id\\\": \\\"SingleEdgeGroup/588b8039-08c4-4041-89bd-e3a36373706c\\\", \\\"type\\\": \\\"SingleEdgeGroup\\\", \\\"edges\\\": [{\\\"source_id\\\": \\\"service_desk_exec\\\", \\\"target_id\\\": \\\"turn_manager\\\"}]}], \\\"executors\\\": {\\\"turn_manager\\\": {\\\"id\\\": \\\"turn_manager\\\", \\\"type\\\": \\\"TurnManager\\\"}, \\\"service_desk_exec\\\": {\\\"id\\\": \\\"service_desk_exec\\\", \\\"type\\\": \\\"AgentExecutor\\\"}}}\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"build.started\",\n",
      "            \"timestamp\": \"2025-11-28T04:53:44.132804Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"build.validation_completed\",\n",
      "            \"timestamp\": \"2025-11-28T04:53:44.138820Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"build.completed\",\n",
      "            \"timestamp\": \"2025-11-28T04:53:44.141332Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"body\": \"Cycle detected in the workflow graph involving: service_desk_exec -> turn_manager -> service_desk_exec. Ensure termination or iteration limits exist.\",\n",
      "    \"severity_number\": 13,\n",
      "    \"severity_text\": \"WARN\",\n",
      "    \"attributes\": {\n",
      "        \"code.file.path\": \"c:\\\\Repos\\\\agent-framework-workshop\\\\.venv\\\\Lib\\\\site-packages\\\\agent_framework\\\\_workflows\\\\_validation.py\",\n",
      "        \"code.function.name\": \"_validate_cycles\",\n",
      "        \"code.line.number\": 520\n",
      "    },\n",
      "    \"dropped_attributes\": 0,\n",
      "    \"timestamp\": \"2025-11-28T04:53:44.134464Z\",\n",
      "    \"observed_timestamp\": \"2025-11-28T04:53:44.137487Z\",\n",
      "    \"trace_id\": \"0x42cb48ba72c8289c4ce815ced3789a4f\",\n",
      "    \"span_id\": \"0x8d3b4210f7f6c626\",\n",
      "    \"trace_flags\": 1,\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    },\n",
      "    \"event_name\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "turn_manager = TurnManager(id=\"turn_manager\")\n",
    "\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(turn_manager)\n",
    "    .add_edge(turn_manager, agent_executor)    # TurnManager -> AgentExecutor\n",
    "    .add_edge(agent_executor, turn_manager)    # AgentExecutor -> TurnManager (respuesta)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Workflow construido con TurnManager + AgentExecutor.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122a1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"Â¿CuÃ¡ntos dÃ­as de vacaciones tengo segÃºn la polÃ­tica?\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¡ Evento: AgentRunEvent(executor_id=service_desk_exec, data=Hola, gracias por tu consulta. SegÃºn la polÃ­tica de la empresa, la cantidad de dÃ­as de vacaciones que tienes disponibles puede variar segÃºn tu antigÃ¼edad y el contrato laboral que tengas. Para brindarte la informaciÃ³n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el Ã¡rea de RRHH directamente.  \n",
      "\n",
      "Si necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle especÃ­fico sobre tus dÃ­as de vacaciones disponibles. Â¿Te parece bien?)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305643673446300,\n",
      "                                        \"count\": 1,\n",
      "                                        \"sum\": 212,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 212,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 212,\n",
      "                                                \"time_unix_nano\": 1764305643624710200,\n",
      "                                                \"span_id\": 15556026081635978474,\n",
      "                                                \"trace_id\": 128444913853793636301915534924591697205\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305643673446300,\n",
      "                                        \"count\": 1,\n",
      "                                        \"sum\": 110,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 110,\n",
      "                                        \"max\": 110,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 110,\n",
      "                                                \"time_unix_nano\": 1764305643626470900,\n",
      "                                                \"span_id\": 15556026081635978474,\n",
      "                                                \"trace_id\": 128444913853793636301915534924591697205\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305643673446300,\n",
      "                                        \"count\": 1,\n",
      "                                        \"sum\": 2.919681099941954,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.919681099941954,\n",
      "                                        \"max\": 2.919681099941954,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 2.919681099941954,\n",
      "                                                \"time_unix_nano\": 1764305643626562100,\n",
      "                                                \"span_id\": 15556026081635978474,\n",
      "                                                \"trace_id\": 128444913853793636301915534924591697205\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x24fddd06d49f9ff3\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x24c060b18b6bb306\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.697014Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:00.697134Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Hola, gracias por tu consulta. SegÃºn la polÃ­tica de la empresa, la cantidad de dÃ­as de vacaciones que tienes disponibles puede variar segÃºn tu antigÃ¼edad y el contrato laboral que tengas. Para brindarte la informaciÃ³n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el Ã¡rea de RRHH directamente.  \n",
      "\n",
      "Si necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle especÃ­fico sobre tus dÃ­as de vacaciones disponibles. Â¿Te parece bien?\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Hola, gracias por tu consulta. SegÃºn la polÃ­tica de la empresa, la cantidad de dÃ­as de vacaciones que tienes disponibles puede variar segÃºn tu antigÃ¼edad y el contrato laboral que tengas. Para brindarte la informaciÃ³n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el Ã¡rea de RRHH directamente.  \n",
      "\n",
      "Si necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle especÃ­fico sobre tus dÃ­as de vacaciones disponibles. Â¿Te parece bien?, source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Hola, gracias por tu consulta. SegÃºn la polÃ­tica de la empresa, la cantidad de dÃ­as de vacaciones que tienes disponibles puede variar segÃºn tu antigÃ¼edad y el contrato laboral que tengas. Para brindarte la informaciÃ³n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el Ã¡rea de RRHH directamente.  \n",
      "\n",
      "Si necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle especÃ­fico sobre tus dÃ­as de vacaciones disponibles. Â¿Te parece bien?\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x24c060b18b6bb306\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x72e8211d5f793436\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.696357Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:00.697175Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0xdda8b89e59cbe4e6\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x72e8211d5f793436\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.699469Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:00.699551Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/f56c0dde-53cd-4aa6-90d0-e946390f7a76\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "                \"span_id\": \"0x24fddd06d49f9ff3\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0xd7e21b4d489fccea\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x8120f3d0e98d0338\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.704737Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.626764Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmWF2yGaNdhcCRnZcmSziWPQ70c\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 212,\n",
      "        \"gen_ai.usage.output_tokens\": 110,\n",
      "        \"gen_ai.client.operation.duration\": 2.919681099941954,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hola, gracias por tu consulta. Seg\\\\u00fan la pol\\\\u00edtica de la empresa, la cantidad de d\\\\u00edas de vacaciones que tienes disponibles puede variar seg\\\\u00fan tu antig\\\\u00fcedad y el contrato laboral que tengas. Para brindarte la informaci\\\\u00f3n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el \\\\u00e1rea de RRHH directamente.  \\\\n\\\\nSi necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle espec\\\\u00edfico sobre tus d\\\\u00edas de vacaciones disponibles. \\\\u00bfTe parece bien?\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x8120f3d0e98d0338\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd5382b89058b95ec\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.700795Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.626999Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"unknown\",\n",
      "        \"gen_ai.agent.id\": \"e855c0f1-3c4a-44c7-bd48-91787f91cc15\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmWF2yGaNdhcCRnZcmSziWPQ70c\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.usage.input_tokens\": 212,\n",
      "        \"gen_ai.usage.output_tokens\": 110,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hola, gracias por tu consulta. Seg\\\\u00fan la pol\\\\u00edtica de la empresa, la cantidad de d\\\\u00edas de vacaciones que tienes disponibles puede variar seg\\\\u00fan tu antig\\\\u00fcedad y el contrato laboral que tengas. Para brindarte la informaci\\\\u00f3n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el \\\\u00e1rea de RRHH directamente.  \\\\n\\\\nSi necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle espec\\\\u00edfico sobre tus d\\\\u00edas de vacaciones disponibles. \\\\u00bfTe parece bien?\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x961ac2c4d7907eb2\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0xd5382b89058b95ec\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.627141Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.627187Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0xd5382b89058b95ec\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x72e8211d5f793436\",\n",
      "    \"start_time\": \"2025-11-28T04:54:00.699665Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.627210Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "                \"span_id\": \"0x24fddd06d49f9ff3\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¡ Evento: AgentRunEvent(executor_id=service_desk_exec, data=Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a travÃ©s de Recursos Humanos.\n",
      "\n",
      "Voy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmarÃ¡n si las fechas estÃ¡n disponibles y si cumplen con las polÃ­ticas actuales. La prioridad del ticket serÃ¡ **media**, ya que no se trata de una solicitud inmediata.  \n",
      "\n",
      "Â¿Me puedes confirmar si estÃ¡s de acuerdo para proceder o si necesitas algo mÃ¡s?)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a travÃ©s de Recursos Humanos.\n",
      "\n",
      "Voy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmarÃ¡n si las fechas estÃ¡n disponibles y si cumplen con las polÃ­ticas actuales. La prioridad del ticket serÃ¡ **media**, ya que no se trata de una solicitud inmediata.  \n",
      "\n",
      "Â¿Me puedes confirmar si estÃ¡s de acuerdo para proceder o si necesitas algo mÃ¡s?\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a travÃ©s de Recursos Humanos.\n",
      "\n",
      "Voy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmarÃ¡n si las fechas estÃ¡n disponibles y si cumplen con las polÃ­ticas actuales. La prioridad del ticket serÃ¡ **media**, ya que no se trata de una solicitud inmediata.  \n",
      "\n",
      "Â¿Me puedes confirmar si estÃ¡s de acuerdo para proceder o si necesitas algo mÃ¡s?, source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a travÃ©s de Recursos Humanos.\n",
      "\n",
      "Voy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmarÃ¡n si las fechas estÃ¡n disponibles y si cumplen con las polÃ­ticas actuales. La prioridad del ticket serÃ¡ **media**, ya que no se trata de una solicitud inmediata.  \n",
      "\n",
      "Â¿Me puedes confirmar si estÃ¡s de acuerdo para proceder o si necesitas algo mÃ¡s?\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "\n",
      "================================================================================\n",
      "ðŸš€ Ejecutando workflow Service Desk con input:\n",
      "\"No puedo conectarme a la VPN y tengo una reuniÃ³n urgente con un cliente.\"\n",
      "\n",
      "ðŸ“¡ Evento: WorkflowStartedEvent(origin=WorkflowEventSource.FRAMEWORK, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IN_PROGRESS, data=None, origin=WorkflowEventSource.FRAMEWORK)\n",
      "ðŸ§­ [TurnManager.start] Enviando AgentExecutorRequest al agente.\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=service_desk_exec, data=None)\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305648691518600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 555,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 343,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 343,\n",
      "                                                \"time_unix_nano\": 1764305645977289600,\n",
      "                                                \"span_id\": 4681148090475203854,\n",
      "                                                \"trace_id\": 321046688850019608681386573925150502879\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305648691518600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 215,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 110,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 105,\n",
      "                                                \"time_unix_nano\": 1764305645977349600,\n",
      "                                                \"span_id\": 4681148090475203854,\n",
      "                                                \"trace_id\": 321046688850019608681386573925150502879\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305648691518600,\n",
      "                                        \"count\": 2,\n",
      "                                        \"sum\": 5.1391066000796854,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            1,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.919681099941954,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 2.2194255001377314,\n",
      "                                                \"time_unix_nano\": 1764305645977366400,\n",
      "                                                \"span_id\": 4681148090475203854,\n",
      "                                                \"trace_id\": 321046688850019608681386573925150502879\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x4f8a50dfda5e4d8f\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x72e8211d5f793436\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.689367Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.689407Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/588b8039-08c4-4041-89bd-e3a36373706c\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "                \"span_id\": \"0x961ac2c4d7907eb2\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x54627a185cdcf1ac\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x72e8211d5f793436\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.689485Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.689614Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "                \"span_id\": \"0x961ac2c4d7907eb2\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x60a197303845e40200792fc9aed48d35\",\n",
      "        \"span_id\": \"0x72e8211d5f793436\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T04:54:00.695082Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.755347Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"5da74c79-fe87-452b-a79b-585ef1426f0e\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:00.695138Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:03.755326Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xa28e4a589a440f79\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x9720f904596068a7\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.756289Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.756324Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0x9720f904596068a7\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x622de1b961253ecc\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.756180Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.756343Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xd5d3044c13b9fcf9\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x622de1b961253ecc\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.756625Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:03.756666Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/f56c0dde-53cd-4aa6-90d0-e946390f7a76\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "                \"span_id\": \"0xa28e4a589a440f79\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0x40f6c762f1c5cd0e\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x715a29e606d21e1f\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.757618Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:05.977494Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hola, gracias por tu consulta. Seg\\\\u00fan la pol\\\\u00edtica de la empresa, la cantidad de d\\\\u00edas de vacaciones que tienes disponibles puede variar seg\\\\u00fan tu antig\\\\u00fcedad y el contrato laboral que tengas. Para brindarte la informaci\\\\u00f3n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el \\\\u00e1rea de RRHH directamente.  \\\\n\\\\nSi necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle espec\\\\u00edfico sobre tus d\\\\u00edas de vacaciones disponibles. \\\\u00bfTe parece bien?\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmY8nt0K6Nug6EjKpX3GznLWeEi\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 343,\n",
      "        \"gen_ai.usage.output_tokens\": 105,\n",
      "        \"gen_ai.client.operation.duration\": 2.2194255001377314,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a trav\\\\u00e9s de Recursos Humanos.\\\\n\\\\nVoy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmar\\\\u00e1n si las fechas est\\\\u00e1n disponibles y si cumplen con las pol\\\\u00edticas actuales. La prioridad del ticket ser\\\\u00e1 **media**, ya que no se trata de una solicitud inmediata.  \\\\n\\\\n\\\\u00bfMe puedes confirmar si est\\\\u00e1s de acuerdo para proceder o si necesitas algo m\\\\u00e1s?\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0x715a29e606d21e1f\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xe167772d500b30c2\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.756835Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:05.977633Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"unknown\",\n",
      "        \"gen_ai.agent.id\": \"e855c0f1-3c4a-44c7-bd48-91787f91cc15\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmY8nt0K6Nug6EjKpX3GznLWeEi\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.usage.input_tokens\": 343,\n",
      "        \"gen_ai.usage.output_tokens\": 105,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a trav\\\\u00e9s de Recursos Humanos.\\\\n\\\\nVoy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmar\\\\u00e1n si las fechas est\\\\u00e1n disponibles y si cumplen con las pol\\\\u00edticas actuales. La prioridad del ticket ser\\\\u00e1 **media**, ya que no se trata de una solicitud inmediata.  \\\\n\\\\n\\\\u00bfMe puedes confirmar si est\\\\u00e1s de acuerdo para proceder o si necesitas algo m\\\\u00e1s?\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xc11a469b94d528be\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0xe167772d500b30c2\",\n",
      "    \"start_time\": \"2025-11-28T04:54:05.977788Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:05.977824Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xe167772d500b30c2\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x622de1b961253ecc\",\n",
      "    \"start_time\": \"2025-11-28T04:54:03.756727Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:05.977848Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "                \"span_id\": \"0xa28e4a589a440f79\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xa5cc75dd677bbd7e\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x622de1b961253ecc\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.037550Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.037591Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/588b8039-08c4-4041-89bd-e3a36373706c\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "                \"span_id\": \"0xc11a469b94d528be\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0xfefeb19663e96156\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x622de1b961253ecc\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.037670Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.037779Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "                \"span_id\": \"0xc11a469b94d528be\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xf18757d959d87ffec093510e180a2fdf\",\n",
      "        \"span_id\": \"0x622de1b961253ecc\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T04:54:03.755953Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.091168Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"5da74c79-fe87-452b-a79b-585ef1426f0e\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:03.755974Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:06.091145Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0xfdcd28c94134b146\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0x26e1da4c18554b02\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.092730Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.092793Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0x26e1da4c18554b02\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xac60828dd13c78be\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.092470Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.092826Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"str\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0xd6c529aa0d7b32c0\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xac60828dd13c78be\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.093295Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:06.093339Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/f56c0dde-53cd-4aa6-90d0-e946390f7a76\",\n",
      "        \"message.source_id\": \"turn_manager\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "                \"span_id\": \"0xfdcd28c94134b146\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "ðŸ“¡ Evento: AgentRunEvent(executor_id=service_desk_exec, data=Entendido, lamento que estÃ©s teniendo este inconveniente. Dado que mencionas que tienes una reuniÃ³n urgente con un cliente, este caso requiere atenciÃ³n prioritaria.\n",
      "\n",
      "Te recomiendo intentar lo siguiente mientras lo resolvemos:\n",
      "\n",
      "1. Verifica que tu conexiÃ³n a internet estÃ© activa.\n",
      "2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\n",
      "3. Confirma que estÃ¡s utilizando las credenciales correctas y que no caducaron.\n",
      "\n",
      "Si estas acciones no resuelven el problema, abrirÃ© de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuniÃ³n con el cliente. \n",
      "\n",
      "Â¿Puedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?)\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=service_desk_exec, data=None)\n",
      "ðŸ“¨ [TurnManager.on_agent_response] Texto del agente:\n",
      " Entendido, lamento que estÃ©s teniendo este inconveniente. Dado que mencionas que tienes una reuniÃ³n urgente con un cliente, este caso requiere atenciÃ³n prioritaria.\n",
      "\n",
      "Te recomiendo intentar lo siguiente mientras lo resolvemos:\n",
      "\n",
      "1. Verifica que tu conexiÃ³n a internet estÃ© activa.\n",
      "2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\n",
      "3. Confirma que estÃ¡s utilizando las credenciales correctas y que no caducaron.\n",
      "\n",
      "Si estas acciones no resuelven el problema, abrirÃ© de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuniÃ³n con el cliente. \n",
      "\n",
      "Â¿Puedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?\n",
      "ðŸ“¡ Evento: ExecutorInvokedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowOutputEvent(data=Entendido, lamento que estÃ©s teniendo este inconveniente. Dado que mencionas que tienes una reuniÃ³n urgente con un cliente, este caso requiere atenciÃ³n prioritaria.\n",
      "\n",
      "Te recomiendo intentar lo siguiente mientras lo resolvemos:\n",
      "\n",
      "1. Verifica que tu conexiÃ³n a internet estÃ© activa.\n",
      "2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\n",
      "3. Confirma que estÃ¡s utilizando las credenciales correctas y que no caducaron.\n",
      "\n",
      "Si estas acciones no resuelven el problema, abrirÃ© de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuniÃ³n con el cliente. \n",
      "\n",
      "Â¿Puedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?, source_executor_id=turn_manager)\n",
      "\n",
      "âœ… Resultado final del workflow:\n",
      "\n",
      "Entendido, lamento que estÃ©s teniendo este inconveniente. Dado que mencionas que tienes una reuniÃ³n urgente con un cliente, este caso requiere atenciÃ³n prioritaria.\n",
      "\n",
      "Te recomiendo intentar lo siguiente mientras lo resolvemos:\n",
      "\n",
      "1. Verifica que tu conexiÃ³n a internet estÃ© activa.\n",
      "2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\n",
      "3. Confirma que estÃ¡s utilizando las credenciales correctas y que no caducaron.\n",
      "\n",
      "Si estas acciones no resuelven el problema, abrirÃ© de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuniÃ³n con el cliente. \n",
      "\n",
      "Â¿Puedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?\n",
      "\n",
      "================================================================================\n",
      "ðŸ“¡ Evento: ExecutorCompletedEvent(executor_id=turn_manager, data=None)\n",
      "ðŸ“¡ Evento: WorkflowStatusEvent(state=WorkflowRunState.IDLE, data=None, origin=WorkflowEventSource.FRAMEWORK)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305653707930400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 471,\n",
      "                                                \"time_unix_nano\": 1764305649066841400,\n",
      "                                                \"span_id\": 3432858962148670202,\n",
      "                                                \"trace_id\": 66495100732971076122580843949665581981\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305653707930400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 153,\n",
      "                                                \"time_unix_nano\": 1764305649066892500,\n",
      "                                                \"span_id\": 3432858962148670202,\n",
      "                                                \"trace_id\": 66495100732971076122580843949665581981\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305653707930400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": [\n",
      "                                            {\n",
      "                                                \"filtered_attributes\": {},\n",
      "                                                \"value\": 2.972697500139475,\n",
      "                                                \"time_unix_nano\": 1764305649066906400,\n",
      "                                                \"span_id\": 3432858962148670202,\n",
      "                                                \"trace_id\": 66495100732971076122580843949665581981\n",
      "                                            }\n",
      "                                        ]\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"name\": \"chat gpt-4o\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0x2fa3f709bae33afa\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0x42e15150970858e5\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.093898Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.067018Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"\\\\u00bfCu\\\\u00e1ntos d\\\\u00edas de vacaciones tengo seg\\\\u00fan la pol\\\\u00edtica?\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hola, gracias por tu consulta. Seg\\\\u00fan la pol\\\\u00edtica de la empresa, la cantidad de d\\\\u00edas de vacaciones que tienes disponibles puede variar seg\\\\u00fan tu antig\\\\u00fcedad y el contrato laboral que tengas. Para brindarte la informaci\\\\u00f3n exacta, te recomiendo que consultes tu perfil en el sistema de Recursos Humanos (si tienes acceso) o que te comuniques con el \\\\u00e1rea de RRHH directamente.  \\\\n\\\\nSi necesitas ayuda con esta consulta, puedo abrir un ticket para que RRHH te proporcione detalle espec\\\\u00edfico sobre tus d\\\\u00edas de vacaciones disponibles. \\\\u00bfTe parece bien?\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, deseas solicitar tus vacaciones del 1 al 15 de agosto. Para proceder con tu solicitud, necesitas que sea gestionada a trav\\\\u00e9s de Recursos Humanos.\\\\n\\\\nVoy a abrir un ticket de tipo **RRHH** para registrar tu solicitud de vacaciones, y ellos te confirmar\\\\u00e1n si las fechas est\\\\u00e1n disponibles y si cumplen con las pol\\\\u00edticas actuales. La prioridad del ticket ser\\\\u00e1 **media**, ya que no se trata de una solicitud inmediata.  \\\\n\\\\n\\\\u00bfMe puedes confirmar si est\\\\u00e1s de acuerdo para proceder o si necesitas algo m\\\\u00e1s?\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"No puedo conectarme a la VPN y tengo una reuni\\\\u00f3n urgente con un cliente.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"openai\",\n",
      "        \"gen_ai.request.model\": \"gpt-4o\",\n",
      "        \"server.address\": \"https://models.github.ai/inference/\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmbbqFqOuSsXcEQZAUqclPQy0k9\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "        \"gen_ai.usage.input_tokens\": 471,\n",
      "        \"gen_ai.usage.output_tokens\": 153,\n",
      "        \"gen_ai.client.operation.duration\": 2.972697500139475,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, lamento que est\\\\u00e9s teniendo este inconveniente. Dado que mencionas que tienes una reuni\\\\u00f3n urgente con un cliente, este caso requiere atenci\\\\u00f3n prioritaria.\\\\n\\\\nTe recomiendo intentar lo siguiente mientras lo resolvemos:\\\\n\\\\n1. Verifica que tu conexi\\\\u00f3n a internet est\\\\u00e9 activa.\\\\n2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\\\\n3. Confirma que est\\\\u00e1s utilizando las credenciales correctas y que no caducaron.\\\\n\\\\nSi estas acciones no resuelven el problema, abrir\\\\u00e9 de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuni\\\\u00f3n con el cliente. \\\\n\\\\n\\\\u00bfPuedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"invoke_agent ServiceDeskAgent\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0x42e15150970858e5\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xdc3ba56db45c9b65\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.093518Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.067137Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"No puedo conectarme a la VPN y tengo una reuni\\\\u00f3n urgente con un cliente.\\\"}]}]\",\n",
      "        \"gen_ai.operation.name\": \"invoke_agent\",\n",
      "        \"gen_ai.request.choice.count\": 1,\n",
      "        \"gen_ai.provider.name\": \"microsoft.agent_framework\",\n",
      "        \"gen_ai.request.model\": \"unknown\",\n",
      "        \"gen_ai.agent.id\": \"e855c0f1-3c4a-44c7-bd48-91787f91cc15\",\n",
      "        \"gen_ai.agent.name\": \"ServiceDeskAgent\",\n",
      "        \"gen_ai.response.id\": \"chatcmpl-CgkmbbqFqOuSsXcEQZAUqclPQy0k9\",\n",
      "        \"gen_ai.response.finish_reasons\": \"[\\\"stop\\\"]\",\n",
      "        \"gen_ai.usage.input_tokens\": 471,\n",
      "        \"gen_ai.usage.output_tokens\": 153,\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Entendido, lamento que est\\\\u00e9s teniendo este inconveniente. Dado que mencionas que tienes una reuni\\\\u00f3n urgente con un cliente, este caso requiere atenci\\\\u00f3n prioritaria.\\\\n\\\\nTe recomiendo intentar lo siguiente mientras lo resolvemos:\\\\n\\\\n1. Verifica que tu conexi\\\\u00f3n a internet est\\\\u00e9 activa.\\\\n2. Reinicia tu equipo y vuelve a intentar conectarte a la VPN.\\\\n3. Confirma que est\\\\u00e1s utilizando las credenciales correctas y que no caducaron.\\\\n\\\\nSi estas acciones no resuelven el problema, abrir\\\\u00e9 de inmediato un ticket de tipo **IT** con **alta prioridad**, ya que impacta directamente en tu reuni\\\\u00f3n con el cliente. \\\\n\\\\n\\\\u00bfPuedes confirmarme si ya intentaste alguna de estas soluciones o si prefieres que registre el ticket de inmediato?\\\"}]}]\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"message.send\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0x28b6191d3ff39d1c\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.PRODUCER\",\n",
      "    \"parent_id\": \"0xdc3ba56db45c9b65\",\n",
      "    \"start_time\": \"2025-11-28T04:54:09.067276Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.067312Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0xdc3ba56db45c9b65\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xac60828dd13c78be\",\n",
      "    \"start_time\": \"2025-11-28T04:54:06.093398Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.067332Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"service_desk_exec\",\n",
      "        \"executor.type\": \"AgentExecutor\",\n",
      "        \"message.type\": \"AgentExecutorRequest\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "                \"span_id\": \"0xfdcd28c94134b146\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"edge_group.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0xb88d426c1ffdef50\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xac60828dd13c78be\",\n",
      "    \"start_time\": \"2025-11-28T04:54:09.124686Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.124792Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"edge_group.type\": \"SingleEdgeGroup\",\n",
      "        \"edge_group.id\": \"SingleEdgeGroup/588b8039-08c4-4041-89bd-e3a36373706c\",\n",
      "        \"message.source_id\": \"service_desk_exec\",\n",
      "        \"edge_group.delivered\": true,\n",
      "        \"edge_group.delivery_status\": \"delivered\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "                \"span_id\": \"0x28b6191d3ff39d1c\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"executor.process\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0x05f74b0283e27f6b\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xac60828dd13c78be\",\n",
      "    \"start_time\": \"2025-11-28T04:54:09.124994Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.125101Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"executor.id\": \"turn_manager\",\n",
      "        \"executor.type\": \"TurnManager\",\n",
      "        \"message.type\": \"AgentExecutorResponse\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"context\": {\n",
      "                \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "                \"span_id\": \"0x28b6191d3ff39d1c\",\n",
      "                \"trace_state\": \"[]\"\n",
      "            },\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"workflow.run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0x32067d95b62a4b558ba32c4a91e87b9d\",\n",
      "        \"span_id\": \"0xac60828dd13c78be\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-11-28T04:54:06.091850Z\",\n",
      "    \"end_time\": \"2025-11-28T04:54:09.190229Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"workflow.id\": \"5da74c79-fe87-452b-a79b-585ef1426f0e\"\n",
      "    },\n",
      "    \"events\": [\n",
      "        {\n",
      "            \"name\": \"workflow.started\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:06.091866Z\",\n",
      "            \"attributes\": {}\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"workflow.completed\",\n",
      "            \"timestamp\": \"2025-11-28T04:54:09.190211Z\",\n",
      "            \"attributes\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.38.0\",\n",
      "            \"service.name\": \"agent_framework\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305658723461300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305658723461300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305658723461300,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305663739620100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305663739620100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305663739620100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "async def run_service_desk_workflow(input_text: str):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ðŸš€ Ejecutando workflow Service Desk con input:\\n\\\"{input_text}\\\"\\n\")\n",
    "\n",
    "    async for event in workflow.run_stream(input_text):\n",
    "        print(\"ðŸ“¡ Evento:\", event)\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(\"\\nâœ… Resultado final del workflow:\\n\")\n",
    "            print(event.data)\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "\n",
    "# Pruebas\n",
    "await run_service_desk_workflow(\"Â¿CuÃ¡ntos dÃ­as de vacaciones tengo segÃºn la polÃ­tica?\")\n",
    "await run_service_desk_workflow(\"Quiero pedir mis vacaciones del 1 al 15 de agosto.\")\n",
    "await run_service_desk_workflow(\"No puedo conectarme a la VPN y tengo una reuniÃ³n urgente con un cliente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f198b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“œ Diagrama Mermaid:\n",
      "\n",
      "flowchart TD\n",
      "  turn_manager[\"turn_manager (Start)\"];\n",
      "  service_desk_exec[\"service_desk_exec\"];\n",
      "  turn_manager --> service_desk_exec;\n",
      "  service_desk_exec --> turn_manager;\n",
      "\n",
      "ðŸ“œ Diagrama DOT:\n",
      "\n",
      "digraph Workflow {\n",
      "  rankdir=TD;\n",
      "  node [shape=box, style=filled, fillcolor=lightblue];\n",
      "  edge [color=black, arrowhead=vee];\n",
      "\n",
      "  \"turn_manager\" [fillcolor=lightgreen, label=\"turn_manager\\n(Start)\"];\n",
      "  \"service_desk_exec\" [label=\"service_desk_exec\"];\n",
      "  \"turn_manager\" -> \"service_desk_exec\";\n",
      "  \"service_desk_exec\" -> \"turn_manager\";\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305678788479200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305678788479200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305678788479200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305683792818200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305683792818200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305683792818200,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305688807665000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305688807665000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305688807665000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "viz = WorkflowViz(workflow)\n",
    "\n",
    "print(\"ðŸ“œ Diagrama Mermaid:\\n\")\n",
    "print(viz.to_mermaid())\n",
    "\n",
    "print(\"\\nðŸ“œ Diagrama DOT:\\n\")\n",
    "print(viz.to_digraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305869107648100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305874121276100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305879124293800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305884139542600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305889156551100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305894168180100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305899174262900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305904191431800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305909206776000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305914208000600,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305919223598100,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305924239821900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305929256574700,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305934272975000,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305939277707800,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305944282393500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305949289163500,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305954291631900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305959306588400,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305964307363900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"resource_metrics\": [\n",
      "        {\n",
      "            \"resource\": {\n",
      "                \"attributes\": {\n",
      "                    \"telemetry.sdk.language\": \"python\",\n",
      "                    \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "                    \"telemetry.sdk.version\": \"1.38.0\",\n",
      "                    \"service.name\": \"agent_framework\"\n",
      "                },\n",
      "                \"schema_url\": \"\"\n",
      "            },\n",
      "            \"scope_metrics\": [\n",
      "                {\n",
      "                    \"scope\": {\n",
      "                        \"name\": \"agent_framework\",\n",
      "                        \"version\": \"1.0.0b251120\",\n",
      "                        \"schema_url\": \"\",\n",
      "                        \"attributes\": null\n",
      "                    },\n",
      "                    \"metrics\": [\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.token.usage\",\n",
      "                            \"description\": \"Captures the token usage of chat clients\",\n",
      "                            \"unit\": \"tokens\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"input\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643625917700,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 1026,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 212,\n",
      "                                        \"max\": 471,\n",
      "                                        \"exemplars\": []\n",
      "                                    },\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\",\n",
      "                                            \"gen_ai.token.type\": \"output\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626540400,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 368,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            3,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            1,\n",
      "                                            4,\n",
      "                                            16,\n",
      "                                            64,\n",
      "                                            256,\n",
      "                                            1024,\n",
      "                                            4096,\n",
      "                                            16384,\n",
      "                                            65536,\n",
      "                                            262144,\n",
      "                                            1048576,\n",
      "                                            4194304,\n",
      "                                            16777216,\n",
      "                                            67108864\n",
      "                                        ],\n",
      "                                        \"min\": 105,\n",
      "                                        \"max\": 153,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"name\": \"gen_ai.client.operation.duration\",\n",
      "                            \"description\": \"Captures the duration of operations of function-invoking chat clients\",\n",
      "                            \"unit\": \"s\",\n",
      "                            \"data\": {\n",
      "                                \"data_points\": [\n",
      "                                    {\n",
      "                                        \"attributes\": {\n",
      "                                            \"gen_ai.operation.name\": \"chat\",\n",
      "                                            \"gen_ai.provider.name\": \"openai\",\n",
      "                                            \"gen_ai.request.model\": \"gpt-4o\",\n",
      "                                            \"server.address\": \"https://models.github.ai/inference/\",\n",
      "                                            \"gen_ai.response.model\": \"gpt-4o-2024-11-20\"\n",
      "                                        },\n",
      "                                        \"start_time_unix_nano\": 1764305643626611200,\n",
      "                                        \"time_unix_nano\": 1764305969308392900,\n",
      "                                        \"count\": 3,\n",
      "                                        \"sum\": 8.11180410021916,\n",
      "                                        \"bucket_counts\": [\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            1,\n",
      "                                            2,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0,\n",
      "                                            0\n",
      "                                        ],\n",
      "                                        \"explicit_bounds\": [\n",
      "                                            0.01,\n",
      "                                            0.02,\n",
      "                                            0.04,\n",
      "                                            0.08,\n",
      "                                            0.16,\n",
      "                                            0.32,\n",
      "                                            0.64,\n",
      "                                            1.28,\n",
      "                                            2.56,\n",
      "                                            5.12,\n",
      "                                            10.24,\n",
      "                                            20.48,\n",
      "                                            40.96,\n",
      "                                            81.92\n",
      "                                        ],\n",
      "                                        \"min\": 2.2194255001377314,\n",
      "                                        \"max\": 2.972697500139475,\n",
      "                                        \"exemplars\": []\n",
      "                                    }\n",
      "                                ],\n",
      "                                \"aggregation_temporality\": 2\n",
      "                            }\n",
      "                        }\n",
      "                    ],\n",
      "                    \"schema_url\": \"\"\n",
      "                }\n",
      "            ],\n",
      "            \"schema_url\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Requiere graphviz instalado en el sistema para exportar a SVG y PNG\n",
    "# https://graphviz.org/download/ \n",
    "\n",
    "# Exportar a SVG\n",
    "svg_path = viz.export(format=\"svg\")\n",
    "print(\"âœ… SVG generado en:\", svg_path)\n",
    "\n",
    "# Exportar a PNG\n",
    "png_path = viz.export(format=\"png\")\n",
    "print(\"âœ… PNG generado en:\", png_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
